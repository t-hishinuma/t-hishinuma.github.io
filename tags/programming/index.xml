<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Programming on hpc::numa.blog()</title>
    <link>https://hishinuma-t.dev/tags/programming/</link>
    <description>Recent content in Programming on hpc::numa.blog()</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Copyright (C) 2020 Toshiaki Hishinuma, All rights reserved.</copyright>
    <lastBuildDate>Tue, 15 Dec 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hishinuma-t.dev/tags/programming/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>混合精度Krylov部分空間法による連立一次方程式の求解について (前編)</title>
      <link>https://hishinuma-t.dev/posts/advent2020/numerical_analysis16/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/advent2020/numerical_analysis16/</guid>
      <description>20201217追記：よくよく読み返してみるとタイトルが「混合精度」なのに話してることが「高精度」だけで精度を混ぜる話なんにもしてないことに気づいたのでこっそり「前編」だったことにしました．後編は今度書きます．
はじめに この記事は数値計算 Advent Calendar 2020の16日目の記事です．
みなさん連立一次方程式解いてますか？
この研究は脳筋マゾヒストが何も分からずにKrylov部分空間法という闇を殴り続けている過程について書きます．
本記事では連立一次方程式解法の1つのカテゴリであるKrylov部分空間法と， Krylov部分空間法を高精度演算で行うことについて扱います．
高精度と聞いて円周率みたいな細かい桁のシミュレーションと思った方, そういう話じゃありません． 本記事ではみなさんが普段やるような1.0e-8とかの近似解を求める場合に高精度演算を使うと良さそうだ．という話をします．
なお，
 Krylov部分空間法の詳しい説明はしませんので詳しいことが知りたい人はSaad大先生の本を読んでください(PDF落ちてます) 作成者はHPCと高精度演算の人なので理論方面の説明はざっくりです このブログでmathjaxを使うのが初で苦戦してます．数式周りは心の目で見てください 最後まで読んでも高精度演算でKrylov部分空間を実装すると便利だなあ！とはなりません．僕の苦しみが共有されるだけです．応用研究に協力してくれる人を募集しています この記事は個人として書いているので所属とは関係ない Qiitaが嫌いなので個人サイトに書いてますが，コメント等あったらTwitterかメールなりで頂けたらと思います  それでは本編を始めます．
 連立一次方程式 $$ Ax = b $$ の求解アルゴリズムは様々なものが提案されています．
(mathjax使えた～よかった～設定疲れた～)
最も有名なものは直接解法に分類されるLU分解 (ガウスの消去法)かと思います．
これはN*Nの行列に対して， \[{2 \over 3}N^3 (後退代入を含む) \] の計算量で求解できる優れたアルゴリズムです．
一方で多くの物理シミュレーションで現れる偏微分方程式などを差分法や有限要素法などを用いて離散化することによって得られる行列は疎行列 (行列の要素がほとんどゼロの行列)です．
疎行列は解析領域を格子分割するなどによって得られ，解析領域を細かく分割することによって離散化誤差を減らし精度の高いシミュレーションを行えますが，行列のサイズは大きくなり求解にかかる時間が増大します．
一般的に離散化により得られる疎行列は格子点数に依存した次元数および各格子点の節点間の接続に依存した非零要素をもつため， このとき1行あたりの非零要素は変わらず，行列の次元数だけが増えていくことが多いため，行列の密度はどんどん減っていきます．
 ※ 1行あたりの非零要素数は元の問題にも依存しますが，多くて100くらいが一般的に思います (例外はいくらでもありますが)．
そのためN*N行の行列全体の非零要素数は100N程度しかないような行列になります．
※ 実際にこのような行列がどのようにして現れるかについては@nqomorita氏が数値計算Advent Calendar 2018で書かれた 有限要素法と反復法線形ソルバのはじめの一歩[前編]などを読んでください (仕事が明らかに忙しいのは知ってますが後編楽しみに待ってます！)
 話を戻すとこのような疎行列はメモリ使用量を節約するために行番号や列番号のインデックス配列を用いて零要素を記憶しない格納形式を用います (詳しくはCRS形式などを調べてください)．
このような疎行列のメモリレイアウトを用いた場合，後から値を挿入(fill-in)したり列方向にアクセスしたりするのが非常に面倒です．
気軽な気持ちで行列行列積なんかした日には結果として密行列が出てくるので台無しです(疎×疎は疎とは限らない)．
そのため疎行列を係数とする連立一次方程式解法では疎行列の値の書き換えや挿入が頻繁に行われるLU分解などの直接解法でなく反復解法がよく使われます． (なお，マルチフロンタル法など疎行列を疎のままでLU分解する手法もありますが，それについては触れません)
Krylov部分空間法と共役勾配法 Krylov部分空間法は， 連立一次方程式$$Ax = b$$ に対する 初期近似解x_0に対応する初期残差ベクトル $$ r_0 = b - Ax_0$$ を用いて Aのべき乗とr_0の積の像が張る空間から近似解を探索する反復法アルゴリズムの一つのカテゴリで， 行列の性質に応じて様々なアルゴリズムがあります．</description>
    </item>
    
    <item>
      <title>混合精度疎行列計算ライブラリDD-AVX v3のv1.0をリリースした</title>
      <link>https://hishinuma-t.dev/posts/tools/dd-avx_v10/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/tools/dd-avx_v10/</guid>
      <description>はじめに DD-AVX_v3という名前なのにv1.0とはこれいかに？
ま，まぁとりあえずリリースしたんじゃよ
githubから落としてこられる↓
https://github.com/t-hishinuma/DD-AVX_v3
DD-AVX_v3ってなに？ 一言でいうとSIMDで高速化した倍精度とDouble-Double精度のSparse BLAS．
混合精度のKrylov部分空間法をいかに簡単かつ高速に実装できるかを考えて作ったライブラリ．
悪条件な問題を解こうとしたとき，高精度演算を使うことで丸め誤差による近似解の収束の影響を抑えて早く収束できる．
ただ，例えば行列は他のライブラリから降ってくるので倍精度でよいとか， 残差の計算は別に倍精度でも良いとか，様々な理由ですべてを倍々精度にしなくても良いというシチュエーションがある．
しかし，変数の精度をどうすれば効率的に計算できるのかはよくわからないし， 普通に考えれば独自型と標準型を組み合わせたコードで変数の型をコロコロ変えるのは吐き気がするレベルで面倒くさい．
私は博士に進学する前は高精度なシミュレーションをやりたいと思ったものだが， 倍精度とDDを組み合わせたKrylov部分空間法を簡単に作るのがそもそも面倒臭すぎる ということで始まったのがDD-AVXライブラリで，色々とI/Fを変えているうちにv3になってしまったということである．
DD型を簡単に扱う方法はBailey, Hida先生のQDライブラリの dd_real 型を使うことになるのだが， ベクトルや行列を std::vector&amp;lt;dd_real&amp;gt; のようにして宣言することになる．
このときメモリレイアウト的には下のようなAoS型になる． これが倍精度と組み合わせて混合精度演算をしたり，並列化をしようとしたときに非常に遅くなる．
そこでSoA型にしようとなるのだが，これは std::vector のようなベクトルを簡単に使うI/Fが利用できなくなる．
じゃあSoA型に気合で std::vector っぽい主要機能を全部書いてやればいいやんけ
これが地獄の始まりでした(車輪の再発明ってレベルじゃないぞ1年かかったわ)
ということでDD-AVX_v3では5つのクラスを提供している．
Scalar  d_real (alias of double) dd_real (provided by the QD Library)  Vector  d_real_vector dd_real_vector  Sparse matrix (CRS format)  d_real_SpMat  スカラやベクタの四則演算レベルから基本的な機能を実装してある． これらはD/DDのキャストや代入などもサポートしているため， 連立一次方程式ソルバをtemplateで実装すれば同じI/Fで倍精度とDD型を使える．
現状ではテスト不足で疎行列型はファイルからのI/Oしかできないのと，SpMVしか実装できないです．v1.1でTSpMVと行列I/Fは追加予定
内部ではすべての方の組み合わせに対してAVX / AVX2のintrinsicsを使って最適化してあるため， どの変数を入れてもDDにキャストされるわけではなく，ちゃんと入力に応じたDDのアルゴリズムが呼ばれるようになっている．
ちなみにaxpyの内部実装はこんな感じ↓
https://github.com/t-hishinuma/DD-AVX_v3/blob/master/src/vector/blas/axpy.cpp
具体的にはBLAS Lv.</description>
    </item>
    
    <item>
      <title>gmpの実装とC&#43;&#43;からの利用法，性能について(1) [gmp multi-precision]</title>
      <link>https://hishinuma-t.dev/posts/gmp/</link>
      <pubDate>Mon, 18 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/gmp/</guid>
      <description>はじめに そろそろTwitterのフォロワーが2500人を迎えるそうです． やはりマイナーな世界だけを深堀りするのでなく， もっと大衆受けする活動をしていくべきだと思いました．
そう，つまりマスに訴えかけることでHPC界のヒカキンのような存在になるのです．
では皆が見てくれるような一般的な話題ってなんなのか？
私は考えました．
google analyticsの結果を見るとこのページはPEZYと4倍精度という検索ワードでくる人がほとんどのようですが， そんな一部の研究者しか使わないものでなく，もっとマスに訴えかけるような，そんなテーマを考えました．
選ばれたのはGNUでした
そう．GNUに媚びて生きていこう．
つまり今回のテーマはGMPです．
なんと四則演算やFFTについて触れます．全国民がオオウケ間違いなし!
明日から倍精度を使うのをやめ，楽しい多倍長ライフが始まるはずです！
まぁ真面目に導入すると，2月頃にgccのfloat128の性能について書いたのがそこそこ閲覧数が多かったので， 他の高精度演算ライブラリについてもちょっと書くかー，と思って第2弾としてGMPを取りあげてみるということです．．
実際はもっと前から書いていたのですが，細部が書けずにいて，2500人だしここで公開しようと思い立って今に至ります．
様々な言語で多倍長整数は標準サポートされることも多くなってきましたが， 浮動小数点に関してはほとんど見かけませんし，実装自体も少ないです．
やはり浮動小数点演算は癖が強い(指数部が伸びるのか，仮数部が伸びるのか，どのくらい時間がかかるのか)や， ツールそのものがどういった機能を持っているかが分かりにくいです．
今回はGMPに着目して，機能面や実装面について紹介していきたいと思います．
ただ，GMPにはいろいろな難しい特徴があり，正直私もあまり詳しい事は言えないので，フォロワー2500人記念とかぶち上げておいてあれですが， 今回の記事では私が現状で知っているGMPの実装についてちゃんとまとめ，使い方と性能を簡単に見ることにします． (GMPで論文何件か書いたとは思えないほど内部の実装に自信がないおじさん)
GMPを用いたプログラム GMPはGNU Multi Precision Arithmetic Libraryのことで，float128などが4倍精度固定であるのに対し， GMPは変数の宣言時，またはどこかでデフォルトの仮数部の精度を指定することで任意の精度型を作ることができます．
ただし，仮数部を自動的に伸ばしたり，自動的に選択するような機能はついていません(そんなことをしたらメモリが大変なことに)．
指数部については固定で，仮数部を指定していくことになります． そのため例題などではよく円周率などが扱われる印象があります．
ここではC++版のgmpxx.hを使ってGMPの多倍長浮動小数点型であるmpf_tのC++ Wrapper, mpf_classを使ってみます． C++版を使えば演算子オーバーロードによって比較的簡単に実装することができます．
すべての変数が同じ精度で良い場合は，mpf_set_default_prec()という関数を使って精度を指定すればよいです． 簡単なプログラムは以下のようになります．
#include&amp;lt;gmpxx.h&amp;gt;#include&amp;lt;iostream&amp;gt;int main(){ mpf_set_default_prec(1024); mpf_class a(1.5); // a = 1.5 	mpf_class b = 1.0; mpf_class c = 0.0; c = a + b; std::cout &amp;lt;&amp;lt; c &amp;lt;&amp;lt; std::endl; return 0; } ね？簡単でしょ？</description>
    </item>
    
    <item>
      <title>数値計算用のベンチマークを取れるコンテナを作っている (OpenBLAS, cuBLAS, fftw, cufft)</title>
      <link>https://hishinuma-t.dev/posts/numa_benchmark/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/numa_benchmark/</guid>
      <description>TL; DR 検索するとCineBenchやゲーム系のベンチマークとかいう何をやっているのか良くわからん結果ばっかりで数値計算の役に立たないのしかでてこない．
STREAMとDGEMM/SGEMMとFFTをCPUとGPUで回してくれるだけでいいんだ！と思うんだけど，冷静に考えるとそういうライブラリってベンチマーク機能が付いてるわけじゃない (てかSTREAMって使いにくいよね．．．)．
ベンチマーク結果はIntelとかNvidiaも出しているけど，アーキごとに項目が整っているとは言いにくい．
数値計算の結果は少ない人数しか興味がなかったのは昔の話で，最近は機械学習の人とかもBLASとかFFTの結果を知りたいはずだから需要がある気がしてるんだけど，統一されたベンチマークがでてくる気配はない．
ベンチマークは比較に意味があるので多くの人が回してくれることが望ましいけど， 我々みたいに自分でOpenBLASだのcuBLASだとfftwだの落としてビルドして，自分でC++でベンチマークコード書いて，自分でsedとかawkとか叩いてgnuplotで整形できる人ばっかりじゃないはず．
そうだ．コンテナ使って数値計算ライブラリの評価が簡単にやれるやつ作ろう．と思い立ってから早かった手作りベンチマークコンテナ
最近はDockerでGPGPUするのも簡単になったしUbuntu 20.04ではDockerがaptで入るようになったしな！
あ，名前は numa_benchmarkにしました．
NUMerical linear Algebra Benchmarkの略であってhishinumaとは関係ありません．本当です．
で，どうやって使うの コードはここにおいて作ってる．ちゃんとCPUとGPUの両方に対応してる．
https://github.com/t-hishinuma/numa_benchmark
コンテナ内に中にrunってコマンドが仕込んであって，実行するとそれを回してくれるようにした．かんたん．
runするとOpenBLASをビルドしていろんなサイズでベンチマークしてくれる．
いまは dot と gemm のベンチマークだけけど， だいたいコンテナ落とす時間も含めて10分くらいで終わるんじゃないかな． 機能面はこれから増やしていくつもり (STREAMはdotがあるからいいかな．．？いいよね．．？)．
DockerHubにも上げてあるので，サイズとかデフォルト設定でいい人は
docker run hishinumat/numa_benchmark run するだけで簡単にベンチマークしてyaml形式で標準出力に結果を出してくる．
サイズとか色々変えたい人はgitからconfigを落としてきて，書き換えて，configのある場所をdockerにマウントすればそのとおりに実行される．
$PWD のマウントで良ければ make benchmark すればdockerコマンド打たなくてよい
git clone git@github.com:t-hishinuma/numa_benchmark.git # vim benchmark_config # if need to change make benchmark 自分でconfigを食わせた場合は結果はresult/に出てくる． せっかくの仮想化だから，pythonのライブラリなんかもコンテナに混ぜて，yamlを元にmatplotlibでプロットしたpngとhtmlも出力してくれるようにした．
でもコードはPythonなんもわからんおじさんすぎてあまりにも適当．
この辺手伝ってくれる人が居たらとても喜びます
結果はこんな感じで，だいたい欲しい情報はでていると思う．
- {&amp;quot;type&amp;quot; : &amp;quot;blas3&amp;quot;, &amp;quot;func&amp;quot; : &amp;quot;sgemm&amp;quot;, &amp;quot;arch&amp;quot; : &amp;quot;cpu&amp;quot;, &amp;quot;# of threads&amp;quot; : 4, &amp;quot;size&amp;quot; : 200, &amp;quot;time [s]&amp;quot; : 0.</description>
    </item>
    
    <item>
      <title>gccの4倍精度の使い方と性能 [gcc quadruple precision]</title>
      <link>https://hishinuma-t.dev/posts/gcc_quad/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/gcc_quad/</guid>
      <description>2011年，5月のリリースでgcc4.6から4倍精度が入った． 昔のブログで軽く使い方を書いたが他のサイトに情報があまり増えてなかったし，私の記事もできが悪かったのでこっちに移転したので改めてまとめてみた．
使い方 簡単な使い方としては， libquadmathを使うことになる．
__float128 型を宣言して使う．倍精度を代入して使うこともできる． 4倍精度数を表現したい場合には後ろに q をつけて使う．
四則演算子や代入なども使えるが，printfだけはchar型の配列に変換してから使う必要がある． 適当なサンプルは以下のとおり：
#include&amp;lt;quadmath.h&amp;gt;#include&amp;lt;stdio.h&amp;gt;int main(){ char str[128]; __float128 a = 1.2345678901234567890q; __float128 b = 1.234; a = a + b; quadmath_snprintf(str,128,&amp;#34;%.40Qf&amp;#34;,a); printf(&amp;#34;%s&amp;#34;,str); return (0); } $ g++ -lquadmath -m128bit-long-double test.c こんな感じに作れる．I/Oがなければ同じプログラムでtemplate使って共通化できるが， I/Oだけは色々調べたがどうしようもなさそうだった．
性能評価 試しに内積を実装して時間を測ってみた．
コードはここにおいた (リポジトリを移動しました, 2020/05/18)．
出力を外に出せば，普通に倍精度と共通化してtemplateで作れた．
gcpで16コアのHaswellマシンを借りて実行してみた．
あんまり参考にはならないが Intel(R) Xeon(R) CPU @ 2.30GHzとのこと．
gccはgcc version 8.2.1 20180905 (Red Hat 8.2.1-3)
OSはCentOS Linux release 8.0.1905 (Core)\
表 各ベクトルサイズにおける倍精度と4倍精度の実行時間 [ms] (-O0, 最適化オプションなし，16 threads)</description>
    </item>
    
  </channel>
</rss>