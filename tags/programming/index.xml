<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Programming on hpc::numa.blog()</title>
    <link>https://hishinuma-t.dev/tags/programming/</link>
    <description>Recent content in Programming on hpc::numa.blog()</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Copyright (C) 2020 Toshiaki Hishinuma, All rights reserved.</copyright>
    <lastBuildDate>Mon, 04 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hishinuma-t.dev/tags/programming/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>数値計算用のベンチマークを取れるコンテナを作っている (OpenBLAS, cuBLAS, fftw, cufft)</title>
      <link>https://hishinuma-t.dev/posts/numa_benchmark/</link>
      <pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/numa_benchmark/</guid>
      <description>TL; DR 検索するとCineBenchやゲーム系のベンチマークとかいう何をやっているのか良くわからん結果ばっかりで数値計算の役に立たないのしかでてこない．
STREAMとDGEMM/SGEMMとFFTをCPUとGPUで回してくれるだけでいいんだ！と思うんだけど，冷静に考えるとそういうライブラリってベンチマーク機能が付いてるわけじゃない (てかSTREAMって使いにくいよね．．．)．
ベンチマーク結果はIntelとかNvidiaも出しているけど，アーキごとに項目が整っているとは言いにくい．
数値計算の結果は少ない人数しか興味がなかったのは昔の話で，最近は機械学習の人とかもBLASとかFFTの結果を知りたいはずだから需要がある気がしてるんだけど，統一されたベンチマークがでてくる気配はない．
ベンチマークは比較に意味があるので多くの人が回してくれることが望ましいけど， 我々みたいに自分でOpenBLASだのcuBLASだとfftwだの落としてビルドして，自分でC++でベンチマークコード書いて，自分でsedとかawkとか叩いてgnuplotで整形できる人ばっかりじゃないはず．
そうだ．コンテナ使って数値計算ライブラリの評価が簡単にやれるやつ作ろう．と思い立ってから早かった手作りベンチマークコンテナ
最近はDockerでGPGPUするのも簡単になったしUbuntu 20.04ではDockerがaptで入るようになったしな！
あ，名前は numa_benchmarkにしました．
NUMerical linear Algebra Benchmarkの略であってhishinumaとは関係ありません．本当です．
で，どうやって使うの コードはここにおいて作ってる．ちゃんとCPUとGPUの両方に対応してる．
https://github.com/t-hishinuma/numa_benchmark
コンテナ内に中にrunってコマンドが仕込んであって，実行するとそれを回してくれるようにした．かんたん．
runするとOpenBLASをビルドしていろんなサイズでベンチマークしてくれる．
いまは dot と gemm のベンチマークだけけど， だいたいコンテナ落とす時間も含めて10分くらいで終わるんじゃないかな． 機能面はこれから増やしていくつもり (STREAMはdotがあるからいいかな．．？いいよね．．？)．
DockerHubにも上げてあるので，サイズとかデフォルト設定でいい人は
docker run hishinumat/numa_benchmark run するだけで簡単にベンチマークしてyaml形式で標準出力に結果を出してくる．
サイズとか色々変えたい人はgitからconfigを落としてきて，書き換えて，configのある場所をdockerにマウントすればそのとおりに実行される．
$PWD のマウントで良ければ make benchmark すればdockerコマンド打たなくてよい
git clone git@github.com:t-hishinuma/numa_benchmark.git # vim benchmark_config # if need to change make benchmark 自分でconfigを食わせた場合は結果はresult/に出てくる． せっかくの仮想化だから，pythonのライブラリなんかもコンテナに混ぜて，yamlを元にmatplotlibでプロットしたpngとhtmlも出力してくれるようにした．
でもコードはPythonなんもわからんおじさんすぎてあまりにも適当．
この辺手伝ってくれる人が居たらとても喜びます
結果はこんな感じで，だいたい欲しい情報はでていると思う．
- {&amp;quot;type&amp;quot; : &amp;quot;blas3&amp;quot;, &amp;quot;func&amp;quot; : &amp;quot;sgemm&amp;quot;, &amp;quot;arch&amp;quot; : &amp;quot;cpu&amp;quot;, &amp;quot;# of threads&amp;quot; : 4, &amp;quot;size&amp;quot; : 200, &amp;quot;time [s]&amp;quot; : 0.</description>
    </item>
    
    <item>
      <title>gccの4倍精度の使い方と性能 [gcc quadruple precision]</title>
      <link>https://hishinuma-t.dev/posts/gcc_quad/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hishinuma-t.dev/posts/gcc_quad/</guid>
      <description>2011年，5月のリリースでgcc4.6から4倍精度が入った． 昔のブログで軽く使い方を書いたが他のサイトに情報があまり増えてなかったし，私の記事もできが悪かったのでこっちに移転したので改めてまとめてみた．
使い方 簡単な使い方としては， libquadmathを使うことになる．
__float128 型を宣言して使う．倍精度を代入して使うこともできる． 4倍精度数を表現したい場合には後ろに q をつけて使う．
四則演算子や代入なども使えるが，printfだけはchar型の配列に変換してから使う必要がある． 適当なサンプルは以下のとおり：
#include&amp;lt;quadmath.h&amp;gt;#include&amp;lt;stdio.h&amp;gt;int main(){ char str[128]; __float128 a = 1.2345678901234567890q; __float128 b = 1.234; a = a + b; quadmath_snprintf(str,128,&amp;#34;%.40Qf&amp;#34;,a); printf(&amp;#34;%s&amp;#34;,str); return (0); } $ g++ -lquadmath -m128bit-long-double test.c こんな感じに作れる．I/Oがなければ同じプログラムでtemplate使って共通化できるが， I/Oだけは色々調べたがどうしようもなさそうだった．
性能評価 試しに内積を実装して時間を測ってみた．
コードはここにおいた (リポジトリを移動しました, 2020/05/18)．
出力を外に出せば，普通に倍精度と共通化してtemplateで作れた．
gcpで16コアのHaswellマシンを借りて実行してみた．
あんまり参考にはならないが Intel(R) Xeon(R) CPU @ 2.30GHzとのこと．
gccはgcc version 8.2.1 20180905 (Red Hat 8.2.1-3)
OSはCentOS Linux release 8.0.1905 (Core)\
表 各ベクトルサイズにおける倍精度と4倍精度の実行時間 [ms] (-O0, 最適化オプションなし，16 threads)</description>
    </item>
    
  </channel>
</rss>